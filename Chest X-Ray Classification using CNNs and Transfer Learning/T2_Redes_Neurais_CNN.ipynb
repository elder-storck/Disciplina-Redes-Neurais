{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elder-storck/Analise-de-logs-do-Wazuh-com-Python/blob/main/Chest%20X-Ray%20Classification%20using%20CNNs%20and%20Transfer%20Learning/T2_Redes_Neurais_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOE2WTDAkagT"
      },
      "source": [
        "# üß†ü§ñ Treinamento de Redes Convolucionais\n",
        "\n",
        "- **Deadline**: 23/12/2025\n",
        "- **Entrega**: O trabalho deve ser entregue via sistema Testr.\n",
        "- **Pontua√ß√£o**: 10 pontos (+1 ponto extra).\n",
        "- O trabalho deve ser realizado individualmente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU05mfhsQB6Y"
      },
      "source": [
        "## Especifica√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdAdEyR69fd1"
      },
      "source": [
        "\n",
        "### Contexto\n",
        "\n",
        "O trabalho consiste em realizar o treinamento de redes neurais convolucionais na base de dados [Chest X-ray Image (COVID19, PNEUMONIA, and NORMAL) dispon√≠vel no kaggle](https://www.kaggle.com/datasets/alsaniipe/chest-x-ray-image). Esta base de dados cont√©m exames de raio-x de pacientes saud√°veis, com pneumonia e com covid19. O objetivo do trabalho √© treinar uma rede neural capaz de identificar se o raio-x pertence a uma pessoa saud√°vel ou com uma das duas doen√ßas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzYAL353TwRd"
      },
      "source": [
        "\n",
        "### Regras\n",
        "\n",
        "- Devem ser treinadas 3 redes neurais, uma customizada (desenvolvida pelo aluno), uma pr√©-treinada com parte convolucional congelada e uma pr√©-treinada  treinada totalmente (*fine-tuning*).\n",
        "- O dataset prov√™ conjuntos de treino e teste. O conjunto de treino deve ser dividido em treino e valida√ß√£o.\n",
        "- O c√≥digo deve ser preparado para utilizar GPUs (no colab ou localmente).\n",
        "- N√£o devem ser utilizados frameworks de alto n√≠vel como keras ou lightning. O c√≥digo deve utilizar apenas pytorch.\n",
        "- Deve ser utilizado data augmentation (o aluno tem liberdade para escolher os m√©todos que fizerem sentido para a tarefa).\n",
        "- Ao final, deve ser apresentados gr√°ficos comparando as acur√°cias de treino e valida√ß√£o ao longo das √©pocas e uma tabela apresentando as m√©tricas de performance revoca√ß√£o, f1-score e acur√°cia para o conjunto de teste em cada configura√ß√£o de rede neural. Al√©m disso, deve ser uma an√°lise qualitativa dos casos de falha.\n",
        "- Por fim, deve ser escrito um texto curto descrevendo e discutindo os resultados. Deve ser explicado com as suas palavras o que as m√©tricas indicam (e.g., o que quer dizer um recall alto para pneumonia, se isto acontecer), se aconteceu overfitting ou se o modelo alcan√ßou uma boa generaliza√ß√£o, se os valores das m√©tricas foram satisfat√≥rios, prov√°veis causas para as falhas e sugest√µes de como melhorar a performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccJn9-T_Ts6e"
      },
      "source": [
        "\n",
        "### Pontos Extras\n",
        "\n",
        "- Receber√° um ponto extra, o aluno que utilizar um m√©todo explainability (e.g., [gradcam++](https://github.com/jacobgil/pytorch-grad-cam)) para mostrar as regi√µes que mais influenciaram a decis√£o da rede neural.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVEGpImEQXLX"
      },
      "source": [
        "### Dicas de Implementa√ß√£o\n",
        "\n",
        "- **Download dos dados**: use a biblioteca `kagglehub` para fazer o download do dataset no colab.\n",
        "\n",
        "- **Cria√ß√£o do dataset**: o pytorch possui a fun√ß√£o [ImageFolder](https://debuggercafe.com/pytorch-imagefolder-for-training-cnn-models/) que torna mais simples a cria√ß√£o de datasets organizados no formato do dataset utilizado no trabalho.\n",
        "\n",
        "- **Leitura e preprocessamento das Imagens**: As imagens do dataset possuem caracter√≠sticas bastante diversas, com algumas delas sendo armazenadas em tons de cinza e outras em RGB, algumas s√£o arquivos BITMAP armazenados em formato jpg, algumas usam 8 bits e outras 16 bits para representar pixels e as resolu√ß√µes das imagens s√£o altamente diferentes. Use a fun√ß√£o abaixo para ler as imagens e lembre-se de realizar *resize* para o tamanho esperado pela rede neural.\n",
        "\n",
        "```python\n",
        "from PIL import Image\n",
        "\n",
        "def load_img(path):\n",
        "  # Le a imagem em diversos formatos e garante que a imagem tenha 3 canais\n",
        "  img = Image.open(path).convert('RGB')\n",
        "  # converte para um tensor do pytorch\n",
        "  img = v2.functional.to_image(img)\n",
        "  # garante que seja uma imagem de 8 bits reescalando os valores adequadamente\n",
        "  img = v2.functional.to_dtype(img, dtype=torch.uint8, scale=True)\n",
        "  return img\n",
        "```\n",
        "\n",
        "- **Aumento de Dados**: Para visualizar a maioria das transforma√ß√µes dispon√≠veis, veja [este site](https://docs.pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html). Use a vers√£o `v2` do pacote `pytorch.transforms`. Veja [este link](https://docs.pytorch.org/vision/main/transforms.html#v2-api-reference-recommended) para uma explica√ß√£o do porqu√™ e instru√ß√µes de uso.\n",
        "  - ‚ö†Ô∏è**IMPORTANTE**‚ö†Ô∏è: o aumento de dados deve ser aplicado apenas no conjunto de treinamento para aumentar a diversidade dos dados. Os dados de valida√ß√£o e teste devem ser **puros e n√£o modificados**, exceto por opera√ß√µes como resize ou normaliza√ß√£o.\n",
        "\n",
        "\n",
        "- **Sele√ß√£o de um modelo pr√©-treinado**: √â uma boa id√©ia experimentar com diferentes modelos pr√©-treinados para avaliar qual vai levar a predi√ß√µes mais corretas e avaliar outros crit√©rios, por exemplo, tempo de forward por imagem. Uma heur√≠stica para escolher modelos √© buscar aqueles que possuem [melhor performance na base de dados ImageNet](https://docs.pytorch.org/vision/0.21/models.html#table-of-all-available-classification-weights:~:text=Table%20of%20all%20available%20classification%20weights).\n",
        "  - As redes mobilenet-v2 e -v3 s√£o desenhadas para serem r√°pidas e rodarem em dispositivos de baixo poder computacional.\n",
        "  - A rede densenet em geral entrega boa performance.\n",
        "  - As Efficientnet-b5+ n√£o rodam no colab (at√© a √∫ltima vez que testei) por falta de mem√≥ria.\n",
        "  - As redes ViT usam a arquitetura transformers e n√£o s√£o convolucionais. **Elas podem ser utilizadas para compara√ß√£o, mas pelo menos uma outra rede neural totalmente convolucional deve ser utilizada**.\n",
        "\n",
        "- **Visualize sempre que poss√≠vel**: N√£o deixe de visualizar pelo menos uma vez os batches que est√£o sendo usados para treinar a rede. Alguma opera√ß√£o pode estar transformando as imagens de forma que a impedir que a rede neural seja capaz de aprender os padr√µes que ela deveria aprender.\n",
        "\n",
        "- **Brinque com Hiperpar√¢metros**: Ajuste os hiperpar√¢metros para tentar chegar em modelos com o m√°ximo de performance de valida√ß√£o. N√£o √© obrigat√≥rio, mas √© legal brincar tamb√©m com t√©cnicas de regulariza√ß√£o, caso a rede esteja sofrendo de overfitting.\n",
        "\n",
        "- **Desbalanceamento do Dataset**: O dataset possui algum n√≠vel de desbalanceamento, com mais imagens normais do que com covid ou pneumonia. N√£o √© obrigat√≥rio, mas quem quiser pode realizar superamostragem dos dados com covid ou pneumonia para mitigar o desbalanceamento. As opera√ß√µes de data augmentation v√£o garantir que os dados tenham diversidade.\n",
        "\n",
        "\n",
        "- **Escrita de tabelas**: Tabelas podem ser escritas em notebooks usando latex, como indicado abaixo.\n",
        "\n",
        "```latex\n",
        "\\begin{array}{ccc}\n",
        "\\hline\n",
        "modelo & m√©trica1 & m√©trica2 \\\\ \\hline\n",
        "custom & 0.85 & 0.83 \\\\ \\hline\n",
        "frozen-conv & 0.91 & 0.92 \\\\ \\hline\n",
        "fine-tuning & 0.93 & 0.90 \\\\ \\hline\n",
        "\\end{array}\n",
        "```\n",
        "\n",
        "O resultado seria:\n",
        "\n",
        "\\begin{array}{ccc}\n",
        "\\hline\n",
        "modelo & m√©trica1 & m√©trica2 \\\\ \\hline\n",
        "custom & 0.85 & 0.83 \\\\ \\hline\n",
        "frozen-conv & 0.91 & 0.92 \\\\ \\hline\n",
        "fine-tuning & 0.93 & 0.90 \\\\ \\hline\n",
        "\\end{array}\n",
        "\n",
        "Elas tamb√©m pode ser escritas em markdown como indicado abaixo:\n",
        "\n",
        "```markdown\n",
        "| modelo | m√©trica1 | m√©trica2 |\n",
        "|---|---|---|\n",
        "| custom | 0.85 | 0.83 |\n",
        "| frozen-conv | 0.91 | 0.92 |\n",
        "| fine-tuning | 0.93 | 0.90 |\n",
        "```\n",
        "\n",
        "O resultado seria:\n",
        "\n",
        "| modelo | m√©trica1 | m√©trica2 |\n",
        "|---|---|---|\n",
        "| custom | 0.85 | 0.83 |\n",
        "| frozen-conv | 0.91 | 0.92 |\n",
        "| fine-tuning | 0.93 | 0.90 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqzQYcpqYT1i"
      },
      "source": [
        "### Roteiro de Implementa√ß√£o\n",
        "\n",
        "Para realizar o trabalho, siga os seguintes passos:\n",
        "\n",
        "1. Fa√ßa o download autom√°tico do dataset.\n",
        "1. Compreenda a organiza√ß√£o do dataset e visualize alguns dados.\n",
        "1. Crie os dataset de treino, valida√ß√£o e teste do pytorch. Visualize se os dados continuam com a mesma cara.\n",
        "1. Crie as transforma√ß√µes de data augmentation e adicione ao dataset de treino.\n",
        "1. Crie transforma√ß√µes para os datasets de valida√ß√£o e teste que coloquem os dados no mesmo formato usado no treino, por exemplo, resize e normaliza√ß√£o. Lembre-se de **N√ÉO** aplicar data augmentation nos conjuntos de valida√ß√£o e teste!\n",
        "1. Crie dataloaders.\n",
        "1. Construa uma CNN.\n",
        "1. Escreva fun√ß√µes para treinamento e avalia√ß√£o. Retorne o valor da acur√°cia para os conjuntos de treino e valida√ß√£o nas √©pocas de treinamento.\n",
        "1. Crie uma loss function e um otimizador.\n",
        "1. Execute o treinamento e verifique se a curva de treinamento est√° se comportando como esperado.\n",
        "  - A acur√°cia de treinamento est√° aumentando? Se n√£o, verifique se o dataset est√° certo e aumente a capacidade da rede.\n",
        "  - A acur√°cia de treinamento se aproximando de 100%? Se n√£o, aumente a capacidade da rede e tente ajustar a learning rate.\n",
        "  - A acur√°cia de valida√ß√£o est√° aumentando no in√≠cio do treinamento? Se n√£o, verifique se os dados de valida√ß√£o est√£o no mesmo formato dos dados de treinamento.\n",
        "  - A acur√°cia de valida√ß√£o est√° diminuindo depois de um n√∫mero de √©pocas? Parece que est√° acontecendo overfitting. Tente usar algum m√©todo de regulariza√ß√£o.  \n",
        "1. Brinque com os hiperpar√¢metros para tentar fazer a rede aprender mais r√°pido e com maior performance de valida√ß√£o.\n",
        "1. Crie uma fun√ß√£o para calcular m√©tricas de avalia√ß√£o e visualize as m√©tricas para os conjuntos de treinamento e teste. Compare os dois e veja se aconteceu overiffitting.\n",
        "\n",
        "Repita o processo usando as redes pr√©-treinadas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "id": "8mmgZcAMoeN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Fa√ßa o download autom√°tico do dataset.\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Fa√ßa o download autom√°tico do dataset.\n",
        "data_dir = 'alsaniipe/chest-x-ray-image'\n",
        "ds_path = kagglehub.dataset_download(data_dir)\n",
        "\n",
        "# Compreenda a organiza√ß√£o do dataset e visualize alguns dados.\n",
        "import os\n",
        "\n",
        "# Diret√≥rio /Data\n",
        "data_dir = os.path.join(ds_path, 'Data')\n",
        "os.listdir(data_dir)\n",
        "\n",
        "# Diret√≥rio /teste\n",
        "os.listdir(os.path.join(data_dir,'test'))\n",
        "# Diret√≥rio /train\n",
        "os.listdir(os.path.join(data_dir,'train'))"
      ],
      "metadata": {
        "id": "WbAnQbfy4cDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Compreenda a organiza√ß√£o do dataset e visualize alguns dados.\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# entrando no dir train\n",
        "train_dir = os.path.join(data_dir,'train')\n",
        "classes = os.listdir(train_dir)\n",
        "print(f\"classes encontradas dentro do train_dir:{classes}\")\n",
        "\n",
        "# entrando classe pneumonia\n",
        "class_dir = os.path.join(train_dir, classes[0])\n",
        "\n",
        "# listando imagens\n",
        "images = os.listdir(class_dir)[:5]\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "for i, img_name in enumerate(images):\n",
        "    img_path = os.path.join(class_dir, img_name)\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(classes[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OuzttJkJffKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Crie os dataset de treino, valida√ß√£o e teste do pytorch. Visualize se os dados continuam com a mesma cara.\n",
        "# 4. Crie as transforma√ß√µes de data augmentation e adicione ao dataset de treino.\n",
        "# 5. Crie transforma√ß√µes para os datasets de valida√ß√£o e teste que coloquem os dados no mesmo formato usado no treino, por exemplo, resize e normaliza√ß√£o. Lembre-se de N√ÉO aplicar data augmentation nos conjuntos de valida√ß√£o e teste!\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "\n",
        "# Transforma√ß√£o COMPLETA para treino (com augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),           # Passo 1: Redimensionar\n",
        "    transforms.RandomCrop(224),              # Passo 2: Crop aleat√≥rio\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Passo 3: Flip\n",
        "    transforms.RandomRotation(degrees=10),   # Passo 4: Rota√ß√£o\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),                   # Passo 5: Converter para tensor\n",
        "    transforms.Normalize(                    # Passo 6: Normalizar\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ),\n",
        "])\n",
        "\n",
        "# Transforma√ß√£o COMPLETA para teste (sem augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),           # Redimensionar\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),                   # Converter para tensor\n",
        "    transforms.Normalize(                    # Normalizar\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ),\n",
        "])\n",
        "\n",
        "# Diretorios dos conjuntos\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "# criando dataset de treino e valida√ß√£o\n",
        "train_dataset_full = datasets.ImageFolder(\n",
        "    root=train_dir,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "val_dataset_full = datasets.ImageFolder(\n",
        "    root=train_dir,\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "# Dividindo Valida√ß√£o de treino\n",
        "indices = np.random.permutation(len(train_dataset_full))\n",
        "train_size = int(0.8 * len(train_dataset_full))\n",
        "train_idx = indices[:train_size]\n",
        "val_idx = indices[train_size:]\n",
        "\n",
        "train_dataset = Subset(train_dataset_full, train_idx)\n",
        "val_dataset   = Subset(val_dataset_full, val_idx)\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root=test_dir,\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "# full_train_dataset = datasets.ImageFolder(\n",
        "#     root=train_dir,\n",
        "#     transform=train_transform\n",
        "# )\n",
        "\n",
        "# # Dividindo Valida√ß√£o de treino\n",
        "# train_size = int(0.8 * len(full_train_dataset))\n",
        "# val_size = len(full_train_dataset) - train_size\n",
        "\n",
        "# train_dataset, val_dataset = random_split(\n",
        "#     full_train_dataset,\n",
        "#     [train_size, val_size]\n",
        "# )\n",
        "\n",
        "# len(train_dataset), len(val_dataset)\n",
        "\n",
        "# test_dataset = datasets.ImageFolder(\n",
        "#     root=test_dir,\n",
        "#     transform=test_transform\n",
        "# )\n",
        "\n",
        "print(\"\\ntrain_data.shape:\", len(train_dataset))\n",
        "print(\"validacao_data.shape:\", len(val_dataset))\n",
        "print(f\"test_data.shape:{len(test_dataset)}\\n\")\n",
        "\n",
        "def denormalize(img, mean, std):\n",
        "    mean = torch.tensor(mean).view(1, 1, 3)\n",
        "    std = torch.tensor(std).view(1, 1, 3)\n",
        "    img = img * std + mean\n",
        "    return img.clamp(0, 1)\n",
        "\n",
        "\n",
        "# Exibe algumas imagens de teste\n",
        "plt.subplot(1, 3, 1)\n",
        "img_tensor, label = train_dataset[0]\n",
        "img = img_tensor.permute(1, 2, 0)\n",
        "img = denormalize(img, mean=[0.485, 0.456, 0.406], std =[0.229, 0.224, 0.225])\n",
        "plt.imshow((img + 1) / 2)\n",
        "plt.title(f'train')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "img_tensor, label = val_dataset[0]\n",
        "img = img_tensor.permute(1, 2, 0)\n",
        "img = denormalize(img, mean=[0.485, 0.456, 0.406], std =[0.229, 0.224, 0.225])\n",
        "plt.imshow((img + 1) / 2)\n",
        "plt.title(f'val')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "img_tensor, label = test_dataset[0]\n",
        "img = img_tensor.permute(1, 2, 0)\n",
        "img = denormalize(img, mean=[0.485, 0.456, 0.406], std =[0.229, 0.224, 0.225])\n",
        "plt.imshow((img + 1) / 2)\n",
        "plt.title(f'test')\n",
        "plt.grid(False)\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "ebe-H8LSocK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Crie dataloaders.\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "validation_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=2)  # shuffling test just to have some variability in the qualitative analysis"
      ],
      "metadata": {
        "id": "7Rc1v-mUji_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo 1 ‚Äî Rede Neural Convolucional Customizada"
      ],
      "metadata": {
        "id": "lMd2Po8AGZFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Construa uma CNN.\n",
        "import torch.nn as nn\n",
        "\n",
        "net = nn.Sequential(\n",
        "    # ========== BLOCO 1 ==========\n",
        "    # Aplica convolu√ß√£o para extrair caracter√≠sticas visuais\n",
        "    nn.Conv2d(3, 32, 5, stride=2),  # Camada convolucional 1\n",
        "    nn.ReLU(),                       # Ativa√ß√£o n√£o-linear\n",
        "    nn.MaxPool2d(2, 2),              # Pooling (redu√ß√£o dimensional)\n",
        "\n",
        "    # ========== BLOCO 2 ==========\n",
        "    # Introduz n√£o-linearidade (sem isso seria apenas uma regress√£o linear)\n",
        "    nn.Conv2d(32, 32, 5, stride=2), # Camada convolucional 2\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    # ========== BLOCO 3 ==========\n",
        "    # Reduz dimens√£o espacial mantendo caracter√≠sticas mais importantes\n",
        "    # Imagem 4x menor (altura/2, largura/2)\n",
        "    nn.Conv2d(32, 32, 5, stride=2), # Camada convolucional 3\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    # ========== CAMADAS DENSAS ==========\n",
        "    nn.Flatten(),                    # Converte 3D ‚Üí 1D\n",
        "    nn.Linear(128, 64),              # Camada totalmente conectada 1\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.3, inplace=False),# Regulariza√ß√£o: \"Desliga\" aleatoriamente 30% dos neur√¥nios durante treino\n",
        "    nn.Linear(64, 3)                 # Camada de sa√≠da (3 classes)\n",
        ")"
      ],
      "metadata": {
        "id": "67RDnqfQt5kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VERIFICA√á√ÉO DE GPU\n",
        "\n",
        "# Retorna True se GPU NVIDIA dispon√≠vel\n",
        "torch.cuda.is_available()\n",
        "\n",
        "device = torch.accelerator.current_accelerator().type \\\n",
        "  if torch.accelerator.is_available() else \"cpu\"\n",
        "\n",
        "# Move TODOS os par√¢metros para GPU/CPU\n",
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "2E1Htl8W_7_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Escreva fun√ß√µes para treinamento e avalia√ß√£o. Retorne o valor da acur√°cia para os conjuntos de treino e valida√ß√£o nas √©pocas de treinamento.\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train_loop(train_loader, net):\n",
        "  net.train()\n",
        "\n",
        "  running_loss = 0.0\n",
        "  all_preds = []\n",
        "  all_labels = []\n",
        "\n",
        "  for data in tqdm(train_loader):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = data\n",
        "      all_labels.extend(labels)\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      all_preds.extend(list(np.argmax(outputs.cpu().detach().numpy(), axis=-1)))\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.cpu().item()\n",
        "\n",
        "  return all_labels, all_preds, running_loss\n",
        "\n",
        "\n",
        "def eval_loop(loader, net):\n",
        "  all_preds = []\n",
        "  all_labels = []\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in tqdm(loader):\n",
        "      images, labels = data\n",
        "      all_labels.extend(labels)\n",
        "\n",
        "      # calculate outputs by running images through the network\n",
        "      images = images.to(device)\n",
        "      outputs = net(images).cpu().numpy()\n",
        "      all_preds.extend(list(np.argmax(outputs, axis=-1)))\n",
        "\n",
        "  return all_labels, all_preds\n"
      ],
      "metadata": {
        "id": "Agf2wNlXoKOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Crie uma loss function e um otimizador.\n",
        "import torch.optim as optim\n",
        "\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer function\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "al4gSzgwiW1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Execute o treinamento e verifique se a curva de treinamento est√° se comportando como esperado.\n",
        "\n",
        "#   A acur√°cia de treinamento est√° aumentando? Se n√£o, verifique se o dataset est√° certo e aumente a capacidade da rede.\n",
        "#   A acur√°cia de treinamento se aproximando de 100%? Se n√£o, aumente a capacidade da rede e tente ajustar a learning rate.\n",
        "#   A acur√°cia de valida√ß√£o est√° aumentando no in√≠cio do treinamento? Se n√£o, verifique se os dados de valida√ß√£o est√£o no mesmo formato dos dados de treinamento.\n",
        "#   A acur√°cia de valida√ß√£o est√° diminuindo depois de um n√∫mero de √©pocas? Parece que est√° acontecendo overfitting. Tente usar algum m√©todo de regulariza√ß√£o.\n",
        "\n",
        "#   Brinque com os hiperpar√¢metros para tentar fazer a rede aprender mais r√°pido e com maior performance de valida√ß√£o.\n",
        "#   Crie uma fun√ß√£o para calcular m√©tricas de avalia√ß√£o e visualize as m√©tricas para os conjuntos de treinamento e teste. Compare os dois e veja se aconteceu overiffitting.\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "history_r1 = []\n",
        "\n",
        "for epoch in range(15):  # loop over the dataset multiple times\n",
        "    # treino\n",
        "    true_train, pred_train, loss_r1 = train_loop(train_loader, net)\n",
        "    train_acc_r1 = accuracy_score(true_train, pred_train)\n",
        "\n",
        "    # valida√ß√£o\n",
        "    true_val, pred_val = eval_loop(validation_loader, net)\n",
        "    val_acc_r1 = accuracy_score(true_val, pred_val)\n",
        "\n",
        "    # Guardar hist√≥rico\n",
        "    history_r1.append([loss_r1, train_acc_r1, val_acc_r1])\n",
        "\n",
        "    print(f\"Epoch {epoch} Loss_train: {loss_r1:.2f} Train acc: {train_acc_r1:.2f} Val acc: {val_acc_r1:.2f}\")"
      ],
      "metadata": {
        "id": "H8ZX8GRSJBEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "true_test, pred_test = eval_loop(test_loader, net)\n",
        "test_acc_r1 = accuracy_score(true_test, pred_test)\n",
        "print(f\"\\nTeste Final: {test_acc_r1:.4f} ({test_acc_r1*100:.2f}%)\")\n",
        "\n",
        "report_r1 = classification_report(true_test, pred_test, output_dict=True)\n",
        "\n",
        "print(classification_report(true_test, pred_test))\n"
      ],
      "metadata": {
        "id": "yzm3uyeztk6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # Import numpy\n",
        "\n",
        "history_r1 = np.array(history_r1)\n",
        "plt.plot(history_r1[:, 1], '-o')\n",
        "# plt.plot(history[:, 2], '-o')\n",
        "plt.plot(history_r1[:, 2], '-o')\n",
        "# plt.plot(test_acc)\n",
        "plt.legend(['train', 'val'])\n"
      ],
      "metadata": {
        "id": "s6GKZh8YqG-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(images, labels, net=None):\n",
        "    prd = None\n",
        "    if net:\n",
        "        with torch.no_grad():\n",
        "            images_gpu = images.to(device)\n",
        "            prd = net(images_gpu).cpu().numpy()\n",
        "        # classe mais provavel por amostra\n",
        "        prd = np.argmax(prd, axis=-1)\n",
        "\n",
        "    n = len(images)\n",
        "    grid_size = int(np.ceil(np.sqrt(n)))\n",
        "\n",
        "    for idx in range(n):\n",
        "        plt.subplot(grid_size, grid_size, idx + 1)\n",
        "        img = images[idx].numpy()\n",
        "\n",
        "        # muda do formato [channels, rows, cols] do torch para [rows, cols, channels]\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "\n",
        "        img = (img + 1) / 2\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.grid(False)\n",
        "        plt.axis('off')\n",
        "        title = f'true: {labels[idx].numpy()}'\n",
        "        if prd is not None:\n",
        "            title += f'\\nprd: {prd[idx]}'\n",
        "        plt.title(title)\n",
        "\n",
        "net.eval()\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "plt.close('all')\n",
        "plt.figure(figsize=(10, 15))\n",
        "show_batch(images, labels, net)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fSC-ofiKsd9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo 2 ‚Äî Rede Pr√©-treinada com Camadas Convolucionais Congeladas"
      ],
      "metadata": {
        "id": "nKxnxBZl8eyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importando o m√≥dulo models do torchvision\n",
        "from torchvision import models\n",
        "\n",
        "# criando uma ResNet-18 pr√©-treinada.\n",
        "net = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "# requires_grad = False impede que os pesos sejam atualizados no treino\n",
        "for param in net.parameters():\n",
        "   param.requires_grad = False\n",
        "\n",
        "net"
      ],
      "metadata": {
        "id": "x2vt-wgz9ay_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.fc"
      ],
      "metadata": {
        "id": "X0PoUF4o-U2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANTE: VERIFICAR O TAMANHO DA IMAGEM DE ENTRADA EM QUE O MODELO FOI PRETREINADO!\n",
        "# ISTO IMPACTA O TAMANHO DA ENTRADA PARA A CAMADA TOTALMENTE CONECTADA!\n",
        "n_in = net.fc.in_features\n",
        "\n",
        "# Substitui a camada de classificacao por uma nova\n",
        "# A ResNet deixa de classificar 1000 classes e passa a classificar 3 classes: NORMAL, PNEUMONIA, COVID19\n",
        "net.fc = nn.Linear(n_in, 3)\n",
        "net = net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
        "optimizer = optim.Adam(net.fc.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "ZHqyPNNT-k3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "history_r2 = []\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    true, pred, loss_r2 = train_loop(train_loader, net)\n",
        "    train_acc_r2 = accuracy_score(true, pred)\n",
        "\n",
        "    true_val, pred_val = eval_loop(validation_loader, net)\n",
        "    val_acc_r2 = accuracy_score(true_val, pred_val)\n",
        "\n",
        "    history_r2.append([loss_r2, train_acc_r2, val_acc_r2])\n",
        "    print(f\"Epoch {epoch} Loss: {loss_r2:.2f} Train acc: {train_acc_r2:.2f} Test acc: {val_acc_r2:.2f} \")\n",
        "\n"
      ],
      "metadata": {
        "id": "ggC4VmIm_dAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_r2 = np.array(history_r2)\n",
        "plt.plot(history_r2[:, 1], '-o')\n",
        "plt.plot(history_r2[:, 2], '-o')\n",
        "plt.legend(['train', 'validation'])"
      ],
      "metadata": {
        "id": "_QCCH-zNAQaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "true_test, pred_test = eval_loop(test_loader, net)\n",
        "test_acc_r2 = accuracy_score(true_test, pred_test)\n",
        "\n",
        "print(f\"\\nTeste Final: {test_acc_r2:.4f} ({test_acc_r2*100:.2f}%)\")\n",
        "\n",
        "report_r2 = classification_report(true_test, pred_test, output_dict=True)\n",
        "\n",
        "\n",
        "print(classification_report(true_test, pred_test))"
      ],
      "metadata": {
        "id": "xxa1BkXDdB0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# true, pred = eval_loop(test_loader, net)\n",
        "\n",
        "# print(classification_report(true, pred))\n",
        "\n",
        "# cm = confusion_matrix(true, pred, labels=list(range(3)))\n",
        "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(3)))\n",
        "# disp.plot(cmap='cividis')\n",
        "# plt.grid(False)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "PKBhAL4nAVi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo 3 ‚Äî Rede Pr√©-treinada com Fine-Tuning Completo"
      ],
      "metadata": {
        "id": "xfq3rAuwGpIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importando o m√≥dulo models do torchvision\n",
        "from torchvision import models\n",
        "\n",
        "# criando uma ResNet-18 pr√©-treinada.\n",
        "net = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "# requires_grad = False impede que os pesos sejam atualizados no treino\n",
        "for param in net.parameters():\n",
        "   param.requires_grad = True\n",
        "\n",
        "net"
      ],
      "metadata": {
        "id": "3Rp7-JoaGw_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.fc"
      ],
      "metadata": {
        "id": "zSizhfK_G5kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANTE: VERIFICAR O TAMANHO DA IMAGEM DE ENTRADA EM QUE O MODELO FOI PRETREINADO!\n",
        "# ISTO IMPACTA O TAMANHO DA ENTRADA PARA A CAMADA TOTALMENTE CONECTADA!\n",
        "n_in = net.fc.in_features\n",
        "\n",
        "# Substitui a camada de classificacao por uma nova\n",
        "# A ResNet deixa de classificar 1000 classes e passa a classificar 3 classes: NORMAL, PNEUMONIA, COVID19\n",
        "net.fc = nn.Linear(n_in, 3)\n",
        "net = net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
        "# optimizer = optim.Adam(net.fc.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "h4X4QEeMG836"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "history_r3 = []\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    true, pred, loss_r3 = train_loop(train_loader, net)\n",
        "    train_acc_r3 = accuracy_score(true, pred)\n",
        "\n",
        "    true_val, pred_val = eval_loop(validation_loader, net)\n",
        "    val_acc_r3 = accuracy_score(true_val, pred_val)\n",
        "\n",
        "    history_r3.append([loss_r3, train_acc_r3, val_acc_r3])\n",
        "    print(f\"Epoch {epoch} Loss: {loss_r3:.2f} Train acc: {train_acc_r3:.2f} Test acc: {val_acc_r3:.2f} \")\n",
        "\n"
      ],
      "metadata": {
        "id": "mtGLVsfLHAUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_r3 = np.array(history_r3)\n",
        "plt.plot(history_r3[:, 1], '-o')\n",
        "plt.plot(history_r3[:, 2], '-o')\n",
        "plt.legend(['train', 'validation'])"
      ],
      "metadata": {
        "id": "fhjZK-_EHEum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "true_test, pred_test = eval_loop(test_loader, net)\n",
        "test_acc_r3 = accuracy_score(true_test, pred_test)\n",
        "print(f\"\\nTeste Final: {test_acc_r3:.4f} ({test_acc_r3*100:.2f}%)\")\n",
        "\n",
        "report_r3 = classification_report(true_test, pred_test, output_dict=True)\n",
        "\n",
        "\n",
        "print(report_r3)"
      ],
      "metadata": {
        "id": "wqzp4zD0HJ5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados Finais\n"
      ],
      "metadata": {
        "id": "XqMbq0GHwpv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# separando os valores do hist√≥rico\n",
        "train_acc = [h[1] for h in history_r1]\n",
        "val_acc   = [h[2] for h in history_r1]\n",
        "\n",
        "epochs = range(1, len(history_r1) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, train_acc, label='Acur√°cia Treino')\n",
        "plt.plot(epochs, val_acc, label='Acur√°cia Valida√ß√£o')\n",
        "\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('Acur√°cia')\n",
        "plt.title('Curva de Acur√°cia ‚Äì Modelo R1')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y1FZytbPwK82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# separando os valores do hist√≥rico\n",
        "train_acc = [h[1] for h in history_r2]\n",
        "val_acc   = [h[2] for h in history_r2]\n",
        "\n",
        "epochs = range(1, len(history_r2) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, train_acc, label='Acur√°cia Treino')\n",
        "plt.plot(epochs, val_acc, label='Acur√°cia Valida√ß√£o')\n",
        "\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('Acur√°cia')\n",
        "plt.title('Curva de Acur√°cia ‚Äì Modelo R2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YWvXMbF8xE-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# separando os valores do hist√≥rico\n",
        "train_acc = [h[1] for h in history_r3]\n",
        "val_acc   = [h[2] for h in history_r3]\n",
        "\n",
        "epochs = range(1, len(history_r3) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, train_acc, label='Acur√°cia Treino')\n",
        "plt.plot(epochs, val_acc, label='Acur√°cia Valida√ß√£o')\n",
        "\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('Acur√°cia')\n",
        "plt.title('Curva de Acur√°cia ‚Äì Modelo R3')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qJUiapvExMWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avalia√ß√£o da Acur√°cia no treinamento\n",
        "No gr√°fico acima, √© poss√≠vel observar que o modelo R1 atingiu uma boa acur√°cia, tanto no conjunto de treino quanto no de teste, permanecendo acima dos 90% a partir da s√©tima √©poca. Lembrando que o valor da LR pode alterar significativamente a acur√°cia do modelo, para o R1 foram testados 0.9e-3 e 1.2e-3, mas o valor 1e-3 foi o que desempenhou melhor, apresentando uma boa acur√°cia e baixas oscila√ß√µes dos resultados por √©pocas.\n",
        "\n",
        "A rede congelada tamb√©m apresentou uma boa acur√°cia; entretanto, esse modelo demonstrou menos varia√ß√µes ao longo do treinamento quando comparado √† rede criada do zero.\n",
        "\n",
        "A rede totalmente treinada apresentou o melhor desempenho. J√° na segunda √©poca, atingiu aproximadamente 92% de acur√°cia e, ao final do treinamento, foi o modelo que apresentou a maior acur√°cia entre as configura√ß√µes avaliadas."
      ],
      "metadata": {
        "id": "xG49ZMP6mY1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# separando os valores do hist√≥rico\n",
        "# Ajustar loss1 para ter o mesmo n√∫mero de √©pocas que os outros modelos para o plot\n",
        "loss1 = [h[0] for h in history_r1[:10]]\n",
        "loss2 = [h[0] for h in history_r2]\n",
        "loss3 = [h[0] for h in history_r3]\n",
        "\n",
        "\n",
        "epochs = range(1, 11)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, loss1, label='loss de R1')\n",
        "plt.plot(epochs, loss2, label='loss de R2')\n",
        "plt.plot(epochs, loss3, label='loss de R3')\n",
        "\n",
        "\n",
        "\n",
        "# plt.plot(epochs, train_acc, label='Acur√°cia Treino')\n",
        "# plt.plot(epochs, val_acc, label='Acur√°cia Valida√ß√£o')\n",
        "\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Curva de fun√ß√£o de perca')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cZ0B6nYXjSIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apesar da an√°lise das curvas de loss de treino indicar converg√™ncia do aprendizado, n√£o foi poss√≠vel avaliar diretamente a ocorr√™ncia de overfitting por meio da compara√ß√£o com a loss de valida√ß√£o ao longo das √©pocas. Dessa forma, a capacidade de generaliza√ß√£o dos modelos foi analisada a partir das m√©tricas de desempenho obtidas no conjunto de teste, como acur√°cia, revoca√ß√£o e F1-score."
      ],
      "metadata": {
        "id": "ppdpD0j7qMm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"recall_r1 = {report_r1['weighted avg']['recall']}\")\n",
        "print(f\"f1_r1     = {report_r1['weighted avg']['f1-score']}\")\n",
        "print(f\"acc_r1    = {test_acc_r1}\")"
      ],
      "metadata": {
        "id": "UbV4E65nyu35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"recall_r2 = {report_r2['weighted avg']['recall']}\")\n",
        "print(f\"f1_r2     = {report_r2['weighted avg']['f1-score']}\")\n",
        "print(f\"acc_r2    = {test_acc_r2}\")"
      ],
      "metadata": {
        "id": "HSNBVlc60qc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"recall_r3 = {report_r3['weighted avg']['recall']}\")\n",
        "print(f\"f1_r3     = {report_r3['weighted avg']['f1-score']}\")\n",
        "print(f\"acc_r3    = {test_acc_r3}\")\n"
      ],
      "metadata": {
        "id": "9sTxYaeQ0q-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desempenho dos modelos no conjunto de teste:\n",
        "\n",
        "\\begin{array}{ccc}\n",
        "\\hline\n",
        "Modelo & Recall & F1-score & Acur√°cia \\\\ \\hline\n",
        "Custom CNN (R1) & 0.9425 & 0.9426 & 0.9425 \\\\ \\hline\n",
        "Frozen Conv (R2) & 0.9114 & 0.9107 & 0.9114 \\\\ \\hline\n",
        "Fine-tuning (R3) & 0.9479 & 0.9487 & 0.9479 \\\\ \\hline\n",
        "\\end{array}\n",
        "\n",
        "Os resultados obtidos no conjunto de teste indicam que o modelo com fine-tuning (R3) apresentou o melhor desempenho geral, superando tanto a CNN treinada do zero (R1) quanto o modelo com camadas convolucionais congeladas (R2). A acur√°cia de 94,79% do modelo R3 demonstra sua maior capacidade de generaliza√ß√£o, ou seja, de classificar corretamente imagens nunca vistas durante o treinamento.\n",
        "\n",
        "A acur√°cia representa a propor√ß√£o total de classifica√ß√µes corretas em rela√ß√£o ao n√∫mero total de amostras do conjunto de teste. J√° a revoca√ß√£o (recall) indica a capacidade do modelo de identificar corretamente os casos positivos, sendo especialmente relevante no contexto m√©dico, pois est√° associada √† redu√ß√£o de falsos negativos. O F1-score, por sua vez, √© a m√©dia harm√¥nica entre precis√£o e recall, refletindo o equil√≠brio entre a detec√ß√£o correta de casos positivos e a minimiza√ß√£o de erros de classifica√ß√£o.\n",
        "\n",
        "Observa-se que, para todos os modelos avaliados, os valores de acur√°cia, recall e F1-score s√£o bastante pr√≥ximos, o que indica um desempenho equilibrado do classificador no conjunto de teste, sem forte tend√™ncia √† ocorr√™ncia de falsos positivos ou falsos negativos. No entanto, o modelo com fine-tuning (R3) apresentou os maiores valores em todas as m√©tricas, evidenciando que o ajuste fino de modelos pr√©-treinados √© foi a melhor estrat√©gia para esse caso de uso."
      ],
      "metadata": {
        "id": "6rqeSWebx3sd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xfq3rAuwGpIz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
